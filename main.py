from etl.extract import get_disruptions
from etl.transform import process_and_save_spark
import datetime

HDFS_PATH = "hdfs://localhost:9000/user/mon_dossier/"  # Modifier avec ton chemin HDFS

if __name__ == "__main__":
    print(f"ğŸš€ DÃ©but du cron exÃ©cutÃ© Ã  {datetime.datetime.now()}")
    data = get_disruptions()
    
    if data:
        process_and_save_spark(data, HDFS_PATH)
        print("âœ… Data processing completed successfully!")
    else:
        print("âš ï¸ Failed to retrieve data.")
    
    print(f"âœ… Fin du cron Ã  {datetime.datetime.now()}")
